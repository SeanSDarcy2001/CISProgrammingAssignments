{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CIS1HW1.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SeanSDarcy2001/CISProgrammingAssignments/blob/main/CIS1HW1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0DY3yzQMfGUT"
      },
      "source": [
        "# Computer Integrated Surgery: Programming Assignment 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x21cE6IYHizO"
      },
      "source": [
        "import csv\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from google.colab import files\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from scipy.optimize import least_squares"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5R7ZOsnfTYl"
      },
      "source": [
        "## PART 1\n",
        "Develop (or develop proficiency with) a Cartesian math package for 3D points, rotations, and frame transformations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kKUvhEhy0WX6"
      },
      "source": [
        "## use package to represent 3D points\n",
        "p1    = np.array([-1489., -4913.,  4345.])\n",
        "p2    = np.array([ 2633., -3268.,  5249.])\n",
        "pcalc = np.array([-3210., -4390.,  3930.])\n",
        "\n",
        "def norm(v):\n",
        "    return v / np.sqrt(np.dot(v, v))"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OdMB1Qv3FUx-",
        "outputId": "cc62050c-36f0-4e85-fb35-d9f43ba512f1"
      },
      "source": [
        "## use packages to represent 3D rotations\n",
        "def identity():\n",
        "  return np.array([[1, 0,  0], [0, 1, 0], [0, 0, 1]])\n",
        "\n",
        "# generate skew matrix from 1x3 array \n",
        "def skew(v) :\n",
        "  skewArg = norm(v)\n",
        "  ax = skewArg[0]\n",
        "  ay = skewArg[1]\n",
        "  az = skewArg[2]\n",
        "  skew = np.array([[0,    -az,  ay],\n",
        "                   [az,   0,    -ax],\n",
        "                   [-ay,  ax,   0]])\n",
        "  return skew\n",
        "\n",
        "# generate 3D Rotation matrix\n",
        "# @Params: alpha, beta, gamma - Rotation angles about the x, y, and z axes respectively\n",
        "# @Returns: 3D Rotation matrix\n",
        "def RotfromAngles(alpha, beta, gamma) :\n",
        "  Rx = np.array([[1, 0,  0], [0, np.cos(alpha), -np.sin(alpha)], [0, np.sin(alpha), np.cos(alpha)]])\n",
        "  Ry = np.array([[np.cos(beta), 0,  np.sin(beta)], [0, 1, 0], [-np.sin(beta), 0, np.cos(beta)]])\n",
        "  Rz = np.array([[np.cos(gamma), -np.sin(gamma),  0], [np.sin(gamma), np.cos(gamma), 0], [0, 0, 1]])\n",
        "  R = RotfromComponents(Rx, Ry, Rz)\n",
        "  return R\n",
        "\n",
        "def smallAngleR(v, theta) :\n",
        "  n = norm(v)\n",
        "  return (identity() + skew(theta * n))\n",
        "\n",
        "def RotfromComponents(Rx, Ry, Rz) :\n",
        "  R = np.dot(np.dot(Rx, Ry), Rz)\n",
        "  return R\n",
        "\n",
        "# convert 3D vector into 4D homogeneous coords\n",
        "def homogenousVector(v, scale) :\n",
        "  Vx = scale * v[0]\n",
        "  Vy = scale * v[1]\n",
        "  Vz = scale * v[2]\n",
        "  return np.array([Vx, Vy, Vz, scale])\n",
        "\n",
        "R = RotfromAngles(0, 1, 0)\n",
        "print(R)\n",
        "\n",
        "# theta = int\n",
        "# RxTheta = np.array([1, 0,  0], [0, np.cos(theta), -np.sin(theta)], [0, np.sin(theta), np.cos(theta)]))\n",
        "# RyTheta"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.54030231  0.          0.84147098]\n",
            " [ 0.          1.          0.        ]\n",
            " [-0.84147098  0.          0.54030231]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdJdE1GGFaod",
        "outputId": "104aaf21-85fb-4ae5-d001-7427c07a9148"
      },
      "source": [
        "## use packages to represent 3D frame transformations\n",
        "\n",
        "class Frame:\n",
        "  \n",
        "  def __init__(self, R, p):\n",
        "    self.R = R\n",
        "    self.p = p\n",
        "    self.F = self.getFrame()\n",
        "\n",
        "  # define Frame using Rotation and Translation\n",
        "  # @Params: Rotation R and Translation p\n",
        "  # @Return: Frame\n",
        "  def getFrame(self):\n",
        "    F = np.row_stack((np.column_stack((self.R, self.p)),\n",
        "                      [0,0,0,1]))\n",
        "    return F\n",
        "\n",
        "  # applies frame transformation to vector\n",
        "  # @Params: Frame F and Vector v\n",
        "  # @Return: transformed vector\n",
        "  def appFrame(self, v):\n",
        "    return np.dot(self.F, v)\n",
        "\n",
        "  # applies inverse frame transformation to vector\n",
        "  # @Params: Frame F and Vector v\n",
        "  # @Return: transformed vector\n",
        "  def appInvFrame(self, v):\n",
        "    Finv = Frame(self.R.T, - (np.dot(self.R.T, self.p)))\n",
        "    return np.dot(Finv.getFrame(), v)\n",
        "\n",
        "# test cases\n",
        "p = np.array([5, 7, 9])\n",
        "F = Frame(R, p)\n",
        "print(F.getFrame())\n",
        "\n",
        "one_t = np.array([[0,0,0],[1,0,0],[0,1,0]])\n",
        "two_t = np.array([[0,0,1], [1,0,1],[0,0,2]])\n",
        "# Transformation is 90 degree rot over x and +1 translation on z\n",
        "# Tested here\n",
        "R = RotfromAngles(90, 0, 0)\n",
        "p = (0,0,1)\n",
        "F = Frame(R, p)\n",
        "n = homogenousVector(one_t[0],1)\n",
        "print((n))\n",
        "print(F.appFrame(n))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.54030231  0.          0.84147098  5.        ]\n",
            " [ 0.          1.          0.          7.        ]\n",
            " [-0.84147098  0.          0.54030231  9.        ]\n",
            " [ 0.          0.          0.          1.        ]]\n",
            "[0 0 0 1]\n",
            "[0. 0. 1. 1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgwajNfLfbRh"
      },
      "source": [
        "# ## example?\n",
        "# n1, n2, ncalc = [norm(p) for p in [p1, p2, pcalc]]\n",
        "\n",
        "# new_zaxis  = norm(np.cross(n1, n2))\n",
        "# new_xaxis  = n1\n",
        "# zero       = np.zeros(3) \n",
        "\n",
        "# fig = plt.figure(figsize=[10, 8])\n",
        "# ax  = fig.add_subplot(1, 1, 1, projection='3d')\n",
        "\n",
        "# x, y, z = zip(zero, new_xaxis)\n",
        "# plt.plot(x, y, z, '-k', linewidth=3)\n",
        "\n",
        "# x, y, z = zip(zero, new_zaxis)\n",
        "# plt.plot(x, y, z, '--k', linewidth=3)\n",
        "\n",
        "# x, y, z = zip(zero, n2)\n",
        "# plt.plot(x, y, z, '-r', linewidth=1)\n",
        "\n",
        "# x, y, z = zip(zero, ncalc)\n",
        "# plt.plot(x, y, z, '--g', linewidth=1)\n",
        "\n",
        "# ax.set_xlim(-1, 1)\n",
        "# ax.set_ylim(-1, 1)\n",
        "# ax.set_zlim(-1, 1)\n",
        "\n",
        "# plt.show()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bRkQybOwfc7k"
      },
      "source": [
        "## PART 2\n",
        "\n",
        "Develop a 3D point set to 3D point set registration algorithm\n",
        "\n",
        "K. Arun, et. al., IEEE PAMI, Vol 9, no 5, pp 698-700, Sept 1987 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAuew8xl6gfb"
      },
      "source": [
        "def rigid_registration(a, b):\n",
        "    a = a.T\n",
        "    b = b.T\n",
        "\n",
        "    # Calculate and subtract means\n",
        "    a_c = np.expand_dims(np.mean(a, axis = 1), axis=1)\n",
        "    b_c = np.expand_dims(np.mean(b, axis = 1), axis=1)\n",
        "    A = a - a_c\n",
        "    B = b - b_c\n",
        "\n",
        "    # Compute SVD\n",
        "    H = np.dot(A, B.T)\n",
        "    U, X, V_t = np.linalg.svd(H)\n",
        "    R = np.dot(V_t.T, U.T)\n",
        "    if (np.allclose(np.linalg.det(R), 1)):\n",
        "        p = b_c - np.matmul(R, a_c)\n",
        "        return Frame(R, p)\n",
        "    elif (np.allclose(np.linalg.det(R), -1)):\n",
        "        assert 0 in H\n",
        "        V = V_t.T\n",
        "        V[:,2] = np.negative(V[:,2])\n",
        "        R = np.dot(V, U.T)\n",
        "        p = b_c - np.matmul(R, a_c)\n",
        "    return Frame(R, p)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IsvWQyYVfB1a",
        "outputId": "cf96b00b-08a7-4dd5-d999-9f8ad6f4f3bf"
      },
      "source": [
        "# Two sets of points to check 3D-3D registration\n",
        "one_t = np.array([[0,0,0],[1,0,0],[0,1,0]])\n",
        "two_t = np.array([[0,0,1], [1,0,1],[0,0,2]])\n",
        "\n",
        "reg = rigid_registration(one_t, two_t)\n",
        "res = np.dot(reg.R, one_t.T) + reg.p\n",
        "if np.allclose(res, two_t.T):\n",
        "    print(\"Success!\")\n",
        "else:\n",
        "    print(\"Registration failed.\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bncF6qwcDNLi"
      },
      "source": [
        "## PART 3\n",
        "\n",
        "Develop a “pivot” calibration method\n",
        "\n",
        "Yaniv 2015 <https://dx.doi.org/10.1117/12.2081348>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpKJSayXDazr"
      },
      "source": [
        "def pivotCalibration(frames) :\n",
        "    \"\"\"\n",
        "    :param frames: N x 4 x 4 ndarray.\n",
        "    :returns: pointer offset, pivot point and RMS Error about centroid of pivot.\n",
        "    \"\"\"\n",
        "    err = -1.0\n",
        "    trans = frames[:, 0:3, 3]\n",
        "\n",
        "    # find pivot point in world coordinates using sphere fitting\n",
        "    pivot = np.concatenate([np.mean(trans, axis=0), np.zeros(1)])\n",
        "\n",
        "    # Compute least squares optimization for unknown point\n",
        "    x_s = trans[:, 0]\n",
        "    y_s = trans[:, 1]\n",
        "    z_s = trans[:, 2]\n",
        "    res = least_squares(func, pivot,\n",
        "                        bounds=((-np.inf, -np.inf, -np.inf, -np.inf),\n",
        "                                (np.inf, np.inf, np.inf, np.inf)),\n",
        "                        jac='3-point',\n",
        "                        args=(x_s, y_s, z_s))\n",
        "\n",
        "    ptr_p = res.x[0:3]\n",
        "\n",
        "    # Calculate mean offset\n",
        "    offsets = np.zeros((frames.shape[0], 3))\n",
        "\n",
        "    rot = frames[:, 0:3, 0:3]\n",
        "    for i, rot in enumerate(rot):\n",
        "        offsets[i] = rot.transpose() @ (ptr_p - trans[i])\n",
        "    ptr_o = np.mean(offsets, axis=0)\n",
        "\n",
        "    # Calculate residual error (root mean square error)\n",
        "\n",
        "    x_v = np.concatenate([ptr_o, ptr_p],axis=0).reshape((6, 1))\n",
        "    num = frames.shape[0]\n",
        "\n",
        "    # Concatenate rotation and -I for each frame\n",
        "    a_0 = (frames[:, 0:3, 0:3]).reshape((3*num,3))\n",
        "    a_1 = (np.eye(3) * -1.0).reshape((1, 3, 3)).repeat(num, 0).reshape((3*num,3))\n",
        "    a_v = np.concatenate((a_0, a_1), axis=1)\n",
        "\n",
        "    # -1 * translation for each frame\n",
        "    b_v = (frames[:, 0:3, 3] * -1.0).reshape(((3*num,1)))\n",
        "\n",
        "    # Compute residuals\n",
        "    resid = (np.dot(a_v, x_v) - b_v)\n",
        "    err = np.sqrt(np.mean(resid * resid))\n",
        "\n",
        "\n",
        "    return ptr_o, ptr_p, err\n",
        "\n",
        "\n",
        "# Function to calculate distance of given\n",
        "# points from center and radius given\n",
        "# by the pivot.\n",
        "def func(pvt, x_s, y_s, z_s):\n",
        "    # Calculate distance from given center\n",
        "    dist = numpy.sqrt((x_s - pvt[0])**2 +\n",
        "                      (y_s - pvt[1])**2 +\n",
        "                      (z_s - pvt[2])**2)\n",
        "\n",
        "    return dist - pvt[3]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-23nGKo8-Xi"
      },
      "source": [
        "## Part 4\n",
        "\n",
        "Given a distortion calibration data set, as described above, compute the “expected” values $\\overrightarrow{C_i}^{(expected)}$ for the $\\overrightarrow{C_i}$:\n",
        "\n",
        "a. For each calibration data frame $[\\overrightarrow{D_1}, ..., \\overrightarrow{D_{N_D}}, \\overrightarrow{A_1}, ..., \\overrightarrow{A_{N_A}}, \\overrightarrow{C_1}, ..., \\overrightarrow{C_{N_C}}]$, compute the transformation between optical tracker $F_D$ and EM tracker coordinates. I.e., compute a frame $F_D$ such that $\\overrightarrow{D_j} = F_D \\cdot \\overrightarrow{d_j}$.\n",
        "\n",
        "b. Similarly, compute a transformation $F_A$ between calibration object and optical tracker coordinates. I.e., $\\overrightarrow{A_j} = F_A \\cdot \\overrightarrow{a_j}$.\n",
        "\n",
        "c. Given $F_D$ and $F_A$, compute $\\overrightarrow{C_i}^{(expected)} = F_D^{-1} \\cdot F_A \\cdot \\overrightarrow{c_j}$.\n",
        "\n",
        "d. Output $\\overrightarrow{C_i}^{(expected)}$ (see file formats below)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivaakJaoi16y"
      },
      "source": [
        "def read_calbody(name):\n",
        "    path = \"https://raw.githubusercontent.com/SeanSDarcy2001/CISProgrammingAssignments/main/data/\" + name + \"-calbody.txt\"\n",
        "    dat = pd.read_csv(path)\n",
        "\n",
        "    N_D, N_A, N_C, FILE = dat.columns\n",
        "    N_D = int(N_D)\n",
        "    N_A = int(N_A) + N_D\n",
        "    N_C = int(N_C) + N_A\n",
        "\n",
        "    dat = dat.to_numpy()\n",
        "    d_coords = dat[0:N_D,   0:3]\n",
        "    a_coords = dat[N_D:N_A, 0:3]\n",
        "    c_coords = dat[N_A:N_C, 0:3]\n",
        "\n",
        "    # Outputs marker types x marker points x coords\n",
        "    return [d_coords, a_coords, c_coords]\n",
        "\n",
        "\n",
        "def read_calreadings(name):\n",
        "    path = \"https://raw.githubusercontent.com/SeanSDarcy2001/CISProgrammingAssignments/main/data/\" + name + \"-calreadings.txt\"\n",
        "    dat = pd.read_csv(path)\n",
        "\n",
        "    N_D, N_A, N_C, N_F, FILE = dat.columns\n",
        "    N_D = int(N_D)\n",
        "    N_A = int(N_A) + N_D\n",
        "    N_C = int(N_C) + N_A\n",
        "    N_F = int(float(N_F))\n",
        "\n",
        "    dat = dat.to_numpy()\n",
        "    D_coords = np.array([dat[0:N_D,   0:3]])\n",
        "    A_coords = np.array([dat[N_D:N_A, 0:3]])\n",
        "    C_coords = np.array([dat[N_A:N_C, 0:3]])\n",
        "    for n in range(1, N_F):\n",
        "        D_coords = np.append(D_coords,\n",
        "                  np.array([dat[((n*N_C)):((n*N_C) + N_D),       0:3]]),\n",
        "                  axis=0)\n",
        "        A_coords = np.append(A_coords,\n",
        "                  np.array([dat[((n*N_C) + N_D):((n*N_C) + N_A), 0:3]]),\n",
        "                  axis=0)\n",
        "        C_coords = np.append(C_coords,\n",
        "                  np.array([dat[((n*N_C) + N_A):((n*N_C) + N_C), 0:3]]),\n",
        "                  axis=0)\n",
        "\n",
        "    # Outputs marker types x frames x marker points x coords\n",
        "    return [D_coords, A_coords, C_coords]\n",
        "\n",
        "def read_empivot(name):\n",
        "    path = \"https://raw.githubusercontent.com/SeanSDarcy2001/CISProgrammingAssignments/main/data/\" + name + \"-empivot.txt\"\n",
        "    dat = pd.read_csv(path)\n",
        "\n",
        "    N_G, N_F, FILE = dat.columns\n",
        "    N_G = int(N_G)\n",
        "    N_F = int(float(N_F))\n",
        "\n",
        "    dat = dat.to_numpy()\n",
        "    G_coords = np.array([dat[0:N_G,   0:3]])\n",
        "    for n in range(1, N_F):\n",
        "        G_coords = np.append(G_coords,\n",
        "                  np.array([dat[((n*N_G)):((n*N_G) + N_G),       0:3]]),\n",
        "                  axis=0)\n",
        "\n",
        "    # Outputs marker types x frames x marker points x coords\n",
        "    return [G_coords]\n",
        "\n",
        "def read_optpivot(name):\n",
        "    path = \"https://raw.githubusercontent.com/SeanSDarcy2001/CISProgrammingAssignments/main/data/\" + name + \"-optpivot.txt\"\n",
        "    dat = pd.read_csv(path)\n",
        "\n",
        "    N_D, N_H, N_F, FILE = dat.columns\n",
        "    N_D = int(N_D)\n",
        "    N_H = int(N_H) + N_D\n",
        "    N_F = int(float(N_F))\n",
        "\n",
        "    dat = dat.to_numpy()\n",
        "    D_coords = np.array([dat[0:N_D,   0:3]])\n",
        "    H_coords = np.array([dat[N_D:N_H, 0:3]])\n",
        "    for n in range(1, N_F):\n",
        "        D_coords = np.append(D_coords,\n",
        "                  np.array([dat[((n*N_H)):((n*N_H) + N_D),       0:3]]),\n",
        "                  axis=0)\n",
        "        H_coords = np.append(H_coords,\n",
        "                  np.array([dat[((n*N_H) + N_D):((n*N_H) + N_H), 0:3]]),\n",
        "                  axis=0)\n",
        "\n",
        "    # Outputs list of marker types x frames x marker points x coords\n",
        "    return [D_coords, H_coords]\n",
        "\n",
        "def read_output(name):\n",
        "    path = \"https://raw.githubusercontent.com/SeanSDarcy2001/CISProgrammingAssignments/main/data/\" + name + \"-output1.txt\"\n",
        "    dat = pd.read_csv(path)\n",
        "\n",
        "    N_C, N_F, FILE = dat.columns\n",
        "    N_C = int(N_C)\n",
        "    N_F = int(float(N_F))\n",
        "\n",
        "    dat = dat.to_numpy()\n",
        "    em_probe = np.array(dat[0, 0:3])\n",
        "    opt_probe = np.array(dat[1, 0:3])\n",
        "    C_coords = np.array([dat[2:N_C,   0:3]])\n",
        "    for n in range(1, N_F):\n",
        "        C_coords = np.append(C_coords,\n",
        "                  np.array([dat[((2+n*N_C)):((2+n*N_C) + N_C),       0:3]]),\n",
        "                  axis=0)\n",
        "\n",
        "    # Outputs list of em_probe, opt_probe, frames x marker points x coords\n",
        "    return [em_probe, opt_probe, C_coords]\n",
        "\n",
        "def write_output(name, em_pt, opt_pt, C_exp):\n",
        "    path = name + '-output1.txt'\n",
        "    with open(path, 'w') as f:\n",
        "        f.write('{}, {}, {}\\n'.format(C_exp.shape[1], C_exp.shape[0], path))\n",
        "        cw = csv.writer(f, delimiter=',')\n",
        "        cw.writerow(em_pt)\n",
        "        cw.writerow(opt_pt)\n",
        "        for frame in range(C_exp.shape[0]):\n",
        "            for marker in range(C_exp.shape[1]):\n",
        "                cw.writerow(C_exp[frame][marker])\n",
        "    files.download(path)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLOwBkmVK8E1"
      },
      "source": [
        "def give_C_exp(name, save=False,\n",
        "               em_pt=np.array([0,0,0]),\n",
        "               opt_pt=np.array([0,0,0])):\n",
        "    # Prepare arrays\n",
        "    calibration_data_frames = read_calreadings(name)\n",
        "    D = calibration_data_frames[0]\n",
        "    A = calibration_data_frames[1]\n",
        "    C = calibration_data_frames[2]\n",
        "    nf = D.shape[0]\n",
        "\n",
        "    tracker_coordinates = read_calbody(name)\n",
        "    em_tracker = tracker_coordinates[0]\n",
        "    opt_tracker = tracker_coordinates[1]\n",
        "    c_vec = tracker_coordinates[2]\n",
        "\n",
        "    C_exp = np.zeros((nf, c_vec.shape[0], 3))\n",
        "    for f in range(nf):\n",
        "        # Compute the transformation between optical\n",
        "        # tracker F_D and EM tracker coordinates\n",
        "        F_D = rigid_registration(em_tracker, D[f])\n",
        "\n",
        "        # Compute the transformation between calibration\n",
        "        # object F_D and optical tracker coordinates\n",
        "        F_A = rigid_registration(opt_tracker, A[f])\n",
        "\n",
        "        # # Compute C_exp\n",
        "        C_exp_temp = np.zeros((1,4))\n",
        "        for nc in range(c_vec.shape[0]):\n",
        "            c_j = np.array([F_D.appInvFrame(F_A.appFrame(homogenousVector(c_vec[nc,:],1)))])\n",
        "            C_exp_temp = np.append(C_exp_temp, c_j, axis=0)\n",
        "        C_exp[f] = C_exp_temp[1:,0:3]\n",
        "    if (save):\n",
        "        write_output(name, em_pt, opt_pt, C_exp)\n",
        "    return C_exp"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znw81JlcMksg"
      },
      "source": [
        "debug_sets = ['pa1-debug-a', 'pa1-debug-b', 'pa1-debug-c', 'pa1-debug-d',\n",
        "              'pa1-debug-e', 'pa1-debug-f', 'pa1-debug-g']\n",
        "\n",
        "unknown_sets = ['pa1-unknown-h', 'pa1-unknown-i', 'pa1-unknown-j']\n",
        "\n",
        "# Run comparisons for debug sets\n",
        "# TODO: TEST PROCEDURE FOR COMPARISON\n",
        "for d in debug_sets:\n",
        "    c = give_C_exp(d, False)\n",
        "\n",
        "# # Export output for unknown sets\n",
        "# for d in debug_sets:\n",
        "#     give_C_exp(d)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yew_jLso-81O"
      },
      "source": [
        "## Part 5\n",
        "\n",
        "Apply the EM tracking data to perform a pivot calibration for the EM probe and determine the position relative to the EM tracker base coordinate system of the dimple in the calibration post. The suggested procedure is as follows.\n",
        "\n",
        "a. Use the first “frame” of pivot calibration data to define a local “probe” coordinate system and use this to compute $\\overrightarrow{g_j}$. One simple method is as follows. First compute the midpoint of the observed points\n",
        "$$\n",
        "\\overrightarrow{G_0} = \\frac{1}{N_G} \\sum \\overrightarrow{G_j}\n",
        "$$\n",
        "Then translate the observations relative to this midpoint. I.e., compute\n",
        "$$\n",
        "\\overrightarrow{g_j} = \\overrightarrow{G_j} - \\overrightarrow{G_0}\n",
        "$$\n",
        "There are alternative methods, many of which involve rotating $\\overrightarrow{g_j}$. But this isn’t particularly critical. Your pivot calibration will determine a tip coordinates $\\overrightarrow{t_G}$ defined in the same probe coordinate system. I.e., if $F_G(t)$ gives the position and orientation of the pointer body at time $t$ with respect to some tracker coordinate system, then $F_G(t) \\cdot \\overrightarrow{t_G}$ gives the coordinates of the pointer tip with respect to the same tracker coordinate system.\n",
        "\n",
        "b. For each “frame” of pivot data, compute a transformation such that $\\overrightarrow{G_j} = F_G[k] \\cdot \\overrightarrow{g_j}$.\n",
        "\n",
        "c. Now use the method discussed in class to solve the system\n",
        "$$\n",
        "\\overrightarrow{P}_{dimple} = F_G[k] \\cdot \\overrightarrow{t_G}\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VfVdAsbGjP2P"
      },
      "source": [
        "def em_pivot_calibration(name):\n",
        "    em_data = read_empivot(name)\n",
        "    G = em_data[0]\n",
        "    nf = G.shape[0]\n",
        "    ng = G.shape[1]\n",
        "\n",
        "    # Use the first \"frame\" of pivot calibration data to define\n",
        "    # a local \"probe\" coordinate system.\n",
        "    first_frame = G[0]\n",
        "    G_0 = np.zeros((1, 3))\n",
        "    for j in range(ng):\n",
        "        G_0 += first_frame[j]\n",
        "    G_0 /= ng\n",
        "\n",
        "    # Now compute g_j\n",
        "    g = np.zeros((ng, 3))\n",
        "    for j in range(ng):\n",
        "        g[j] = first_frame[j] - G_0\n",
        "\n",
        "    # Compute F_G transforms using rigid registration\n",
        "    F_G = np.array((1, 4, 4))\n",
        "    for k in range(nf):\n",
        "        np.append(F_G, rigid_registration(g, G[k]))\n",
        "\n",
        "    em_pt = (pivotCalibration(F_G[1:,:,:]))[1]\n",
        "    return em_pt"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jJpPmoz6-jQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "outputId": "29735557-699b-43f2-be50-91e80997cac5"
      },
      "source": [
        "em_pivot_calibration('pa1-debug-a')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-a9212f81d5a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mem_pivot_calibration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pa1-debug-a'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-12-9eb911524b84>\u001b[0m in \u001b[0;36mem_pivot_calibration\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF_G\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrigid_registration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mem_pt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpivotCalibration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF_G\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-3f53631d0ab3>\u001b[0m in \u001b[0;36mrigid_registration\u001b[0;34m(a, b)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mV\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mV_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mV\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnegative\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3d-bsQld_Cah"
      },
      "source": [
        "## Part 6\n",
        "\n",
        "Apply the optical tracking data to perform a pivot calibration of the optical tracking probe. The suggested method is the same as above except that you should first use your value for $F_D$ to transform the optical tracker beacon positions into EM tracker coordinates. Note that the optical tracker may not be in exactly the same position and orientation with respect to the EM tracker base for each observation frame of optical tracker data, so this is an important step."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myF8UpHojO9X"
      },
      "source": [
        "def opt_pivot_calibration(name):\n",
        "    opt_data = read_optpivot(name)\n",
        "    tracker_coordinates = read_calbody(name)\n",
        "    em_tracker = tracker_coordinates[0]\n",
        "    \n",
        "    D = opt_data[0]\n",
        "    H = opt_data[1]\n",
        "    nf = D.shape[0]\n",
        "    nd = D.shape[1]\n",
        "    nh = H.shape[1]\n",
        "    print(H.shape)\n",
        "\n",
        "    # Use F_D value to transform D's into d's (EM coordinates)\n",
        "    F_D = rigid_registration(em_tracker, D[0])\n",
        "\n",
        "    # Use the first \"frame\" of pivot calibration data to define\n",
        "    # a local \"probe\" coordinate system.\n",
        "    first_frame = H[0]\n",
        "\n",
        "    H_0 = np.zeros((1, 3))\n",
        "    for j in range(nh):\n",
        "        first_frame[j] = F_D.appFrame(homogenousVector(first_frame[j], 1))[:3]\n",
        "        H_0 += first_frame[j]\n",
        "    H_0 /= nh\n",
        "\n",
        "    # Now compute h_j\n",
        "    h = np.zeros((nh, 3))\n",
        "    for j in range(nh):\n",
        "        h[j] = first_frame[j] - H_0\n",
        "\n",
        "    # Compute F_D transforms using rigid registration\n",
        "    F_H = np.array((1, 4, 4))\n",
        "    for k in range(nf):\n",
        "        F_D = rigid_registration(em_tracker, D[k])\n",
        "        for j in range(nh):\n",
        "            H[k][j] = F_D.appFrame(homogenousVector(H[k][j], 1))[:3]\n",
        "        np.append(F_H, rigid_registration(h, H[k]))\n",
        "\n",
        "    opt_pt = (pivotCalibration(F_H[1:,:,:]))[1]\n",
        "    return opt_pt"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADiYrNW6EnxJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "outputId": "1e7e6a8e-551b-494a-8594-d80e61ca0400"
      },
      "source": [
        "opt_pivot_calibration('pa1-debug-a')"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(12, 6, 3)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-697d92230c92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mopt_pivot_calibration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pa1-debug-a'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-35-e494420bf64a>\u001b[0m in \u001b[0;36mopt_pivot_calibration\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mH\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF_D\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhomogenousVector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF_H\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrigid_registration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mopt_pt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpivotCalibration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF_H\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-3f53631d0ab3>\u001b[0m in \u001b[0;36mrigid_registration\u001b[0;34m(a, b)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mV\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mV_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mV\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnegative\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7D4ZPJudtq-G"
      },
      "source": [
        "# Contributions\n",
        "\n",
        "## Seby\n",
        "\n",
        "\n",
        "*   developed proficiency with a Cartesian math package for 3D points rotations, and frame transformations. (1)\n",
        "*   documented functionality and variable significance\n",
        "\n",
        "\n",
        "## Alex\n",
        "\n",
        "\n",
        "*   developed proficiency with a Cartesian math package for 3D points rotations, and frame transformations. (1)\n",
        "*   created Frame object with transformation functionality. (1)\n",
        "*   developed algorithm for 3D-3D registration. (2)\n",
        "*   developed method for pivot calibration using sphere fitting. (3)\n",
        "*   developed methods for reading in files for application. (4-6)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3Mb-BuajoLb"
      },
      "source": [
        "<!-- #callibration object\n",
        "\n",
        "#N_c is set of EM tracked points on callibration object relative to calibration object frame Fc (known)\n",
        "#N_a is set of optically tracked points on callibration object relative to calibration object frame Fc (known)\n",
        "#N_d are optically tracked points on base of EM tracker relative to EM base (known)\n",
        "#A_j are optically tracked points on callibration object relative to optical tracker (highly accurate)\n",
        "#D_j are optically tracked points on base of EM tracker relative to optical tracker (highly accurate)\n",
        "#C_i are measured positions of EM tracked points on callibration object relative to EM tracker, subject to distortion and noise v.\n",
        "\n",
        "#data is [D, A, C]\n",
        "#wish to recover \n",
        "\n",
        "#pointer probes\n",
        "\n",
        "#N_h is set of optically tracked points on one pointer probe relative to pointer frame (fixed, unknown)\n",
        "#N_g is set of EM tracked points on other pointer probe relative to pointer frame (fixed, unknown)\n",
        "#H_i is set of optically tracked points on pointer probe relative to optical tracker (highly accurate)\n",
        "#G_i is set of EM tracked points on other pointer probe relative to EM tracker, subject to distortion and noise v.\n",
        "\n",
        "#data is [D, H] and [G]\n",
        "#wish to recover \n",
        "#wish to recover position of pivot dimple relative to EM tracker base  -->"
      ]
    }
  ]
}