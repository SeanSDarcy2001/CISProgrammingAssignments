{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lungNoduleUNet.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNOniNaMZ90pDQCgQt/4Nei",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SeanSDarcy2001/CISProgrammingAssignments/blob/main/downstreamTasks/lung/lungNoduleUNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "directory = \"gdrive/My Drive/deepDRR_3dseg\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uoqRZPavC8wy",
        "outputId": "3190d1cb-176c-43b9-83c8-b1366b382cfb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms \n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from skimage import io\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class DoubleConv(nn.Module):\n",
        "    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
        "        super().__init__()\n",
        "        if not mid_channels:\n",
        "            mid_channels = out_channels\n",
        "        self.double_conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(mid_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.double_conv(x)\n",
        "\n",
        "\n",
        "class Down(nn.Module):\n",
        "    \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
        "\n",
        "    #might need to add padding here?\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.down_conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=2, bias=False),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.down_conv(x)\n",
        "\n",
        "\n",
        "class Up(nn.Module):\n",
        "    \"\"\"Upscaling then double conv\"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
        "        super().__init__()\n",
        "\n",
        "        # if bilinear, use the normal convolutions to reduce the number of channels\n",
        "        if bilinear:\n",
        "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "            self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n",
        "        else:\n",
        "            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=3, stride=2)\n",
        "            self.conv = DoubleConv(in_channels, out_channels)\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        x1 = self.up(x1)\n",
        "        # input is CHW\n",
        "        diffY = x2.size()[2] - x1.size()[2]\n",
        "        diffX = x2.size()[3] - x1.size()[3]\n",
        "\n",
        "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
        "                        diffY // 2, diffY - diffY // 2])\n",
        "        x = torch.cat([x2, x1], dim=1)\n",
        "        return self.conv(x)\n",
        "\n",
        "\n",
        "class OutConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(OutConv, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
        "        self.sig = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        return self.sig(x)"
      ],
      "metadata": {
        "id": "vYdupXtKLw_U"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "w6ooV7bFLn0Z"
      },
      "outputs": [],
      "source": [
        "class UNet(nn.Module):\n",
        "    def __init__(self, n_channels, n_classes, bilinear=False):\n",
        "        super(UNet, self).__init__()\n",
        "        self.n_channels = n_channels\n",
        "        self.n_classes = n_classes\n",
        "        self.bilinear = bilinear\n",
        "\n",
        "        self.inc = DoubleConv(n_channels, 16)\n",
        "        self.down1 = Down(16, 32)\n",
        "        self.down2 = Down(32, 64)\n",
        "        self.down3 = Down(64, 128)\n",
        "        factor = 2 if bilinear else 1\n",
        "        self.down4 = Down(128, 256 // factor)\n",
        "        self.up1 = Up(256, 128 // factor, bilinear)\n",
        "        self.up2 = Up(128, 64 // factor, bilinear)\n",
        "        self.up3 = Up(64, 32 // factor, bilinear)\n",
        "        self.up4 = Up(32, 16, bilinear)\n",
        "        self.outc = OutConv(16, n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.inc(x)\n",
        "        x2 = self.down1(x1)\n",
        "        x3 = self.down2(x2)\n",
        "        x4 = self.down3(x3)\n",
        "        x5 = self.down4(x4)\n",
        "        x = self.up1(x5, x4)\n",
        "        x = self.up2(x, x3)\n",
        "        x = self.up3(x, x2)\n",
        "        x = self.up4(x, x1)\n",
        "        logits = self.outc(x)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Image Transforms\n",
        "img_transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "\n",
        "## Image Dataloader\n",
        "class ImageDataset(Dataset):\n",
        "    \n",
        "    \"\"\"\n",
        "    ImageDataset\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self,\n",
        "                 input_dir,\n",
        "                 transforms=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            input_dir (str): Path to either colorization or segmentation directory\n",
        "            op (str): One of \"train\", \"val\", or \"test\" signifying the desired split\n",
        "            mask_json_path (str): Path to mapping.json file\n",
        "            transforms (list or None): Image transformations to apply upon loading.\n",
        "        \"\"\"\n",
        "        self.transform = transforms\n",
        "        self.data_dir = input_dir\n",
        "        self.cases = os.listdir(os.path.join(self.data_dir, \"images\"))\n",
        "    \n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"\n",
        "        \n",
        "        \"\"\"\n",
        "        return len(next(os.walk(self.data_dir))[1])\n",
        "\n",
        "    def __getitem__(self,\n",
        "                    idx):\n",
        "        \"\"\"\n",
        "        \n",
        "        \"\"\"\n",
        "        case = self.cases[idx - 1]\n",
        "\n",
        "        img = io.imread(os.path.join(self.data_dir, \"images\", case))\n",
        "        mask = io.imread(os.path.join(self.data_dir, \"masks\", case))\n",
        "      \n",
        "        ## Transform image and mask\n",
        "        if self.transform:\n",
        "            img, mask = self.img_transform(img, mask)\n",
        "\n",
        "        #mask = F.one_hot(mask, num_classes = 2)\n",
        "      \n",
        "        return img, mask\n",
        "\n",
        "    def img_transform(self,\n",
        "                      img,\n",
        "                      mask):\n",
        "        \"\"\"\n",
        "        \n",
        "        \"\"\"\n",
        "        ## Apply Transformations to Image and Mask\n",
        "        img = self.transform(img)\n",
        "        mask = self.transform(mask)\n",
        "        return img, mask"
      ],
      "metadata": {
        "id": "cE6xr6mnWM7f"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dice_score_image(prediction, target, n_classes):\n",
        "    '''\n",
        "      computer the mean dice score for a single image\n",
        "\n",
        "      Reminders: A false positive is a result that indicates a given condition exists, when it does not\n",
        "               A false negative is a test result that indicates that a condition does not hold, while in fact it does\n",
        "      Args:\n",
        "          prediction (tensor): predictied labels of the image\n",
        "          target (tensor): ground truth of the image\n",
        "          n_classes (int): number of classes\n",
        "    \n",
        "      Returns:\n",
        "          m_dice (float): Mean dice score over classes\n",
        "    '''\n",
        "\n",
        "    smooth = 1\n",
        "    prediction = prediction[0]\n",
        "    target=target[0]\n",
        "    prediction = prediction.view(-1, prediction.size(0) * prediction.size(1)).cpu().numpy() \n",
        "    dice_classes = np.zeros(n_classes)\n",
        "\n",
        "    for cl in range(n_classes): \n",
        "      label = target[cl]\n",
        "      label = label.view(-1, label.size(0) * label.size(1)).cpu().numpy() \n",
        "      TP = 0\n",
        "      FP = 0\n",
        "      FN = 0\n",
        "      for i in range(len(label[0][:])):\n",
        "        if label[0][i] == 1 and prediction[0][i] == cl: \n",
        "          TP += 1 \n",
        "        elif label[0][i] == 0 and prediction[0][i] == cl:\n",
        "          FP += 1 \n",
        "        elif label[0][i] == 1 and prediction[0][i] != cl:\n",
        "          FN += 1 \n",
        "      #When there is no grount truth of the class in this image\n",
        "      #Give 1 dice score if False Positive pixel number is 0,\n",
        "      #give 0 dice score if False Positive pixel number is not 0 (> 0). \n",
        "      if (TP + FN == 0):\n",
        "        if FP == 0: \n",
        "          dice_classes[cl] = 1\n",
        "        else: \n",
        "          dice_classes[cl] = 0 \n",
        "      else:\n",
        "        dice_classes[cl] = (2*TP+smooth)/(2*TP+FN+FP+smooth) \n",
        "    return dice_classes.mean()\n",
        "\n",
        "\n",
        "def dice_score_dataset(model, dataloader, num_classes, use_gpu=False):\n",
        "    \"\"\"\n",
        "    Compute the mean dice score on a set of data.\n",
        "    \n",
        "    Note that multiclass dice score can be defined as the mean over classes of binary\n",
        "    dice score. Dice score is computed per image. Mean dice score over the dataset is the dice\n",
        "    score averaged across all images.\n",
        "    \n",
        "    Reminders: A false positive is a result that indicates a given condition exists, when it does not\n",
        "               A false negative is a test result that indicates that a condition does not hold, while in fact it does\n",
        "     \n",
        "    Args:\n",
        "        model (UNET class): Your trained model\n",
        "        dataloader (DataLoader): Dataset for evaluation\n",
        "        num_classes (int): Number of classes\n",
        "    \n",
        "    Returns:\n",
        "        m_dice (float): Mean dice score over the input dataset\n",
        "    \"\"\"\n",
        "    ## Number of Batches and Cache over Dataset \n",
        "    n_batches = len(dataloader)\n",
        "    scores = np.zeros(n_batches)\n",
        "    ## Evaluate\n",
        "    model.eval()\n",
        "    idx = 0\n",
        "    for data in dataloader:\n",
        "        ## Format Data\n",
        "        img, target = data\n",
        "        if use_gpu:\n",
        "            img = img.cuda()\n",
        "            target = target.cuda()\n",
        "        ## Make Predictions\n",
        "        out = model(img)\n",
        "        #print(n_classes)\n",
        "        prediction = torch.argmax(out, dim = 1)\n",
        "        #print(prediction[0])\n",
        "        scores[idx] = dice_score_image(prediction, target, n_classes)\n",
        "        idx += 1\n",
        "    ## Average Dice Score Over Images\n",
        "    m_dice = scores.mean()\n",
        "    return m_dice\n",
        "\n",
        "class DICELoss(nn.Module):\n",
        "    def __init__(self):\n",
        "      super(DICELoss, self).__init__()\n",
        "    \n",
        "    def forward(self, out, target):\n",
        "        smoothing = 1\n",
        "        intersect = (out * target).sum(dim = 2).sum(dim = 2)\n",
        "        diceScore = (2.* intersect + smoothing) / (smoothing + out.sum(dim=2).sum(dim=2) + target.sum(dim =2).sum(dim = 2))\n",
        "        loss = torch.mean(1 - diceScore) \n",
        "        return loss"
      ],
      "metadata": {
        "id": "cGy-6JL5BdhT"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Batch Size\n",
        "train_batch_size = 1\n",
        "\n",
        "## Learning Rate\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Epochs (Consider setting high and implementing early stopping)\n",
        "num_epochs = 200"
      ],
      "metadata": {
        "id": "4JOyrHdZCc33"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_classes = 2\n",
        "model = UNet(1, n_classes)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    model.cuda()\n",
        "\n",
        "## Initialize Dataloaders\n",
        "train_dataset=ImageDataset(input_dir=directory, transforms=img_transform)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=train_batch_size, shuffle=False)\n",
        "\n",
        "## Initialize Optimizer and Learning Rate Scheduler\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate, betas = [.9, .999])\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
        "\n",
        "#Losses\n",
        "lossfxn = DICELoss()\n",
        "\n",
        "\n",
        "print(\"Start Training...\")\n",
        "\n",
        "tLoss = []\n",
        "vLoss = []\n",
        "\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    ########################### Training #####################################\n",
        "    print(\"\\nEPOCH \" +str(epoch+1)+\" of \"+str(num_epochs)+\"\\n\")\n",
        "\n",
        "  \n",
        "\n",
        "    model.train()\n",
        "    batchLoss = []\n",
        "    for data in train_dataloader:\n",
        "        optimizer.zero_grad()\n",
        "        ## Format Data\n",
        "        img, target = data\n",
        "        img = img.cuda()\n",
        "        target = target.cuda()\n",
        "        ## Make Predictions\n",
        "        #out = model(img)\n",
        "        #prediction = torch.argmax(model(img), dim = 1)\n",
        "        l = lossfxn(model(img), target)\n",
        "        batchLoss.append(l.item())\n",
        "        l.backward()\n",
        "        optimizer.step()\n",
        "    epochLoss = np.mean(batchLoss)\n",
        "    tLoss.append(epochLoss)\n",
        "    scheduler.step()\n",
        "    print(\"Training Loss:\", epochLoss)\n",
        "  \n",
        "\n",
        "  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "J2x5j1CpCP6p",
        "outputId": "6004afc9-20af-45ae-e981-52aa4732d583"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start Training...\n",
            "\n",
            "EPOCH 1 of 200\n",
            "\n",
            "Training Loss: 0.996692419052124\n",
            "\n",
            "EPOCH 2 of 200\n",
            "\n",
            "Training Loss: 0.9961113731066386\n",
            "\n",
            "EPOCH 3 of 200\n",
            "\n",
            "Training Loss: 0.9955704808235168\n",
            "\n",
            "EPOCH 4 of 200\n",
            "\n",
            "Training Loss: 0.9955242077509562\n",
            "\n",
            "EPOCH 5 of 200\n",
            "\n",
            "Training Loss: 0.9950094421704611\n",
            "\n",
            "EPOCH 6 of 200\n",
            "\n",
            "Training Loss: 0.9948886632919312\n",
            "\n",
            "EPOCH 7 of 200\n",
            "\n",
            "Training Loss: 0.9946417411168417\n",
            "\n",
            "EPOCH 8 of 200\n",
            "\n",
            "Training Loss: 0.9946794509887695\n",
            "\n",
            "EPOCH 9 of 200\n",
            "\n",
            "Training Loss: 0.9944619337717692\n",
            "\n",
            "EPOCH 10 of 200\n",
            "\n",
            "Training Loss: 0.9943185846010844\n",
            "\n",
            "EPOCH 11 of 200\n",
            "\n",
            "Training Loss: 0.9941792885462443\n",
            "\n",
            "EPOCH 12 of 200\n",
            "\n",
            "Training Loss: 0.9941595991452535\n",
            "\n",
            "EPOCH 13 of 200\n",
            "\n",
            "Training Loss: 0.9941262205441793\n",
            "\n",
            "EPOCH 14 of 200\n",
            "\n",
            "Training Loss: 0.9940953056017557\n",
            "\n",
            "EPOCH 15 of 200\n",
            "\n",
            "Training Loss: 0.9940719803174337\n",
            "\n",
            "EPOCH 16 of 200\n",
            "\n",
            "Training Loss: 0.9940452377001444\n",
            "\n",
            "EPOCH 17 of 200\n",
            "\n",
            "Training Loss: 0.9940088589986166\n",
            "\n",
            "EPOCH 18 of 200\n",
            "\n",
            "Training Loss: 0.9939751227696737\n",
            "\n",
            "EPOCH 19 of 200\n",
            "\n",
            "Training Loss: 0.9939441482226054\n",
            "\n",
            "EPOCH 20 of 200\n",
            "\n",
            "Training Loss: 0.9939118226369222\n",
            "\n",
            "EPOCH 21 of 200\n",
            "\n",
            "Training Loss: 0.9938910007476807\n",
            "\n",
            "EPOCH 22 of 200\n",
            "\n",
            "Training Loss: 0.9938878814379374\n",
            "\n",
            "EPOCH 23 of 200\n",
            "\n",
            "Training Loss: 0.9938843647638956\n",
            "\n",
            "EPOCH 24 of 200\n",
            "\n",
            "Training Loss: 0.9938807288805643\n",
            "\n",
            "EPOCH 25 of 200\n",
            "\n",
            "Training Loss: 0.9938770532608032\n",
            "\n",
            "EPOCH 26 of 200\n",
            "\n",
            "Training Loss: 0.9938735365867615\n",
            "\n",
            "EPOCH 27 of 200\n",
            "\n",
            "Training Loss: 0.9938700795173645\n",
            "\n",
            "EPOCH 28 of 200\n",
            "\n",
            "Training Loss: 0.9938666224479675\n",
            "\n",
            "EPOCH 29 of 200\n",
            "\n",
            "Training Loss: 0.9938632249832153\n",
            "\n",
            "EPOCH 30 of 200\n",
            "\n",
            "Training Loss: 0.993859867254893\n",
            "\n",
            "EPOCH 31 of 200\n",
            "\n",
            "Training Loss: 0.9938574632008871\n",
            "\n",
            "EPOCH 32 of 200\n",
            "\n",
            "Training Loss: 0.9938571254412333\n",
            "\n",
            "EPOCH 33 of 200\n",
            "\n",
            "Training Loss: 0.9938568274180094\n",
            "\n",
            "EPOCH 34 of 200\n",
            "\n",
            "Training Loss: 0.9938564697901408\n",
            "\n",
            "EPOCH 35 of 200\n",
            "\n",
            "Training Loss: 0.9938561121622721\n",
            "\n",
            "EPOCH 36 of 200\n",
            "\n",
            "Training Loss: 0.9938557744026184\n",
            "\n",
            "EPOCH 37 of 200\n",
            "\n",
            "Training Loss: 0.9938554565111796\n",
            "\n",
            "EPOCH 38 of 200\n",
            "\n",
            "Training Loss: 0.9938550988833109\n",
            "\n",
            "EPOCH 39 of 200\n",
            "\n",
            "Training Loss: 0.9938547611236572\n",
            "\n",
            "EPOCH 40 of 200\n",
            "\n",
            "Training Loss: 0.9938544034957886\n",
            "\n",
            "EPOCH 41 of 200\n",
            "\n",
            "Training Loss: 0.9938541650772095\n",
            "\n",
            "EPOCH 42 of 200\n",
            "\n",
            "Training Loss: 0.9938541452089945\n",
            "\n",
            "EPOCH 43 of 200\n",
            "\n",
            "Training Loss: 0.9938540856043497\n",
            "\n",
            "EPOCH 44 of 200\n",
            "\n",
            "Training Loss: 0.9938540458679199\n",
            "\n",
            "EPOCH 45 of 200\n",
            "\n",
            "Training Loss: 0.9938540458679199\n",
            "\n",
            "EPOCH 46 of 200\n",
            "\n",
            "Training Loss: 0.9938539862632751\n",
            "\n",
            "EPOCH 47 of 200\n",
            "\n",
            "Training Loss: 0.9938539266586304\n",
            "\n",
            "EPOCH 48 of 200\n",
            "\n",
            "Training Loss: 0.9938539266586304\n",
            "\n",
            "EPOCH 49 of 200\n",
            "\n",
            "Training Loss: 0.9938539067904154\n",
            "\n",
            "EPOCH 50 of 200\n",
            "\n",
            "Training Loss: 0.9938538273175558\n",
            "\n",
            "EPOCH 51 of 200\n",
            "\n",
            "Training Loss: 0.9938538074493408\n",
            "\n",
            "EPOCH 52 of 200\n",
            "\n",
            "Training Loss: 0.9938538074493408\n",
            "\n",
            "EPOCH 53 of 200\n",
            "\n",
            "Training Loss: 0.9938538074493408\n",
            "\n",
            "EPOCH 54 of 200\n",
            "\n",
            "Training Loss: 0.9938538074493408\n",
            "\n",
            "EPOCH 55 of 200\n",
            "\n",
            "Training Loss: 0.9938538074493408\n",
            "\n",
            "EPOCH 56 of 200\n",
            "\n",
            "Training Loss: 0.9938538074493408\n",
            "\n",
            "EPOCH 57 of 200\n",
            "\n",
            "Training Loss: 0.9938538074493408\n",
            "\n",
            "EPOCH 58 of 200\n",
            "\n",
            "Training Loss: 0.9938538074493408\n",
            "\n",
            "EPOCH 59 of 200\n",
            "\n",
            "Training Loss: 0.9938538074493408\n",
            "\n",
            "EPOCH 60 of 200\n",
            "\n",
            "Training Loss: 0.9938538074493408\n",
            "\n",
            "EPOCH 61 of 200\n",
            "\n",
            "Training Loss: 0.9938538074493408\n",
            "\n",
            "EPOCH 62 of 200\n",
            "\n",
            "Training Loss: 0.9938538074493408\n",
            "\n",
            "EPOCH 63 of 200\n",
            "\n",
            "Training Loss: 0.9938538074493408\n",
            "\n",
            "EPOCH 64 of 200\n",
            "\n",
            "Training Loss: 0.9938538074493408\n",
            "\n",
            "EPOCH 65 of 200\n",
            "\n",
            "Training Loss: 0.9938538074493408\n",
            "\n",
            "EPOCH 66 of 200\n",
            "\n",
            "Training Loss: 0.9938538074493408\n",
            "\n",
            "EPOCH 67 of 200\n",
            "\n",
            "Training Loss: 0.9938538074493408\n",
            "\n",
            "EPOCH 68 of 200\n",
            "\n",
            "Training Loss: 0.9938538074493408\n",
            "\n",
            "EPOCH 69 of 200\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-411e98296fd0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;31m## Format Data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;31m## Make Predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}